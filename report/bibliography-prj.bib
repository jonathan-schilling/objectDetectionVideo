@article{aydin2023,
  title = {Drone {{Detection Using YOLOv5}}},
  author = {Aydin, Burchan and Singha, Subroto},
  year = {2023},
  month = feb,
  journal = {Eng},
  volume = {4},
  number = {1},
  pages = {416--433},
  issn = {2673-4117},
  doi = {10.3390/eng4010025},
  urldate = {2023-10-10},
  abstract = {The rapidly increasing number of drones in the national airspace, including those for recreational and commercial applications, has raised concerns regarding misuse. Autonomous drone detection systems offer a probable solution to overcoming the issue of potential drone misuse, such as drug smuggling, violating people's privacy, etc. Detecting drones can be difficult, due to similar objects in the sky, such as airplanes and birds. In addition, automated drone detection systems need to be trained with ample amounts of data to provide high accuracy. Real-time detection is also necessary, but this requires highly configured devices such as a graphical processing unit (GPU). The present study sought to overcome these challenges by proposing a one-shot detector called You Only Look Once version 5 (YOLOv5), which can train the proposed model using pre-trained weights and data augmentation. The trained model was evaluated using mean average precision (mAP) and recall measures. The model achieved a 90.40\% mAP, a 21.57\% improvement over our previous model that used You Only Look Once version 4 (YOLOv4) and was tested on the same dataset.},
  langid = {english}
}

@article{bie2023,
  title = {Real-time vehicle detection algorithm based on a lightweight {{You-Only-Look-Once}} ({{YOLOv5n-L}}) approach},
  author = {Bie, Minglin and Liu, Yanyan and Li, Guoning and Hong, Jintao and Li, Jin},
  year = {2023},
  month = mar,
  journal = {Expert Systems with Applications},
  volume = {213},
  pages = {119108},
  issn = {09574174},
  doi = {10.1016/j.eswa.2022.119108},
  urldate = {2023-10-10},
  langid = {english}
}

@inproceedings{girshick1994,
  title = {Feature hierarchies for accurate object detection and semantic segmentation},
  booktitle = {Proc. of the {{IEEE}} conf. on computer vision and pattern recognition},
  author = {Girshick, R and Donahue, J and Darrell, T and Rich, J Malik},
  year = {1994},
  pages = {580--587}
}

@inproceedings{girshick2015,
  title = {Fast {{R-CNN}}},
  booktitle = {Proceedings of the {{IEEE}} international conference on computer vision ({{ICCV}})},
  author = {Girshick, Ross},
  year = {2015},
  month = dec
}

@misc{jocher2020,
  title = {{{YOLOv5}} by {{Ultralytics}}},
  author = {Jocher, Glenn},
  year = {2020},
  month = may,
  doi = {10.5281/zenodo.3908559},
  urldate = {2023-10-10},
  copyright = {AGPL-3.0}
}

@misc{jocher2023,
  title = {{{YOLO}} by {{Ultralytics}}},
  author = {Jocher, Glenn and Chaurasia, Ayush and Qiu, Jing},
  year = {2023},
  month = jan,
  url = {https://github.com/ultralytics/ultralytics},
  urldate = {2023-10-10},
  copyright = {AGPL-3.0}
}

@misc{kovacevic,
  title = {Esports},
  author = {Kovacevic, Aleksandar},
  journal = {game},
  url = {https://www.game.de/en/esport/},
  urldate = {2023-10-06},
  langid = {english},
  file = {/Users/jonathan/Zotero/storage/D6JEQ4KP/esport.html}
}

@incollection{lin2014,
  title = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  shorttitle = {Microsoft {{COCO}}},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2014},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C. Lawrence},
  editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  year = {2014},
  volume = {8693},
  pages = {740--755},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-10602-1_48},
  urldate = {2023-10-10},
  isbn = {978-3-319-10601-4 978-3-319-10602-1},
  langid = {english}
}

@article{majumder2023,
  title = {Automated {{Vehicle Counting}} from {{Pre-Recorded Video Using You Only Look Once}} ({{YOLO}}) {{Object Detection Model}}},
  author = {Majumder, Mishuk and Wilmot, Chester},
  year = {2023},
  month = jun,
  journal = {Journal of Imaging},
  volume = {9},
  number = {7},
  pages = {131},
  issn = {2313-433X},
  doi = {10.3390/jimaging9070131},
  urldate = {2023-10-10},
  abstract = {Different techniques are being applied for automated vehicle counting from video footage, which is a significant subject of interest to many researchers. In this context, the You Only Look Once (YOLO) object detection model, which has been developed recently, has emerged as a promising tool. In terms of accuracy and flexible interval counting, the adequacy of existing research on employing the model for vehicle counting from video footage is unlikely sufficient. The present study endeavors to develop computer algorithms for automated traffic counting from pre-recorded videos using the YOLO model with flexible interval counting. The study involves the development of algorithms aimed at detecting, tracking, and counting vehicles from pre-recorded videos. The YOLO model was applied in TensorFlow API with the assistance of OpenCV. The developed algorithms implement the YOLO model for counting vehicles in two-way directions in an efficient way. The accuracy of the automated counting was evaluated compared to the manual counts, and was found to be about 90 percent. The accuracy comparison also shows that the error of automated counting consistently occurs due to undercounting from unsuitable videos. In addition, a benefit\textendash cost (B/C) analysis shows that implementing the automated counting method returns 1.76 times the investment.},
  langid = {english}
}

@inproceedings{redmon2016,
  title = {You only look once: {{Unified}}, real-time object detection},
  booktitle = {Proceedings of the {{IEEE}} conference on computer vision and pattern recognition ({{CVPR}})},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  year = {2016},
  month = jun
}

@misc{riotgames-valorant,
  title = {Valorant},
  author = {Riot Games},
  url = {https://playvalorant.com/},
  urldate = {2023-10-06},
  langid = {english},
  file = {/Users/jonathan/Zotero/storage/RI4QH3UY/en-us.html}
}

@misc{riotgames-vct,
  title = {Valorant {{Esports}}},
  author = {Riot Games},
  url = {https://valorantesports.com/},
  urldate = {2023-10-06},
  file = {/Users/jonathan/Zotero/storage/FZNTLPHF/valorantesports.com.html}
}

@misc{river2021,
  title = {I tried to make a {{Valorant AI}} using computer vision},
  author = {River's Education Channel},
  year = {2021},
  month = may,
  url = {https://www.youtube.com/watch?v=LXA7zXVz8A4},
  urldate = {2023-10-06},
  file = {/Users/jonathan/Zotero/storage/EV7TCIDC/watch.html}
}

@misc{spike2023,
  title = {Spike},
  year = {2023},
  month = oct,
  journal = {Valorant Wiki},
  url = {https://valorant.fandom.com/wiki/Spike},
  urldate = {2023-10-09},
  langid = {english},
  file = {/Users/jonathan/Zotero/storage/M658D4RV/Spike.html}
}

@article{terven2023,
  title = {A {{Comprehensive Review}} of {{YOLO}}: {{From YOLOv1}} and {{Beyond}}},
  shorttitle = {A {{Comprehensive Review}} of {{YOLO}}},
  author = {Terven, Juan and {Cordova-Esparza}, Diana},
  year = {2023},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2304.00501},
  urldate = {2023-10-10},
  abstract = {YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO's evolution, examining the innovations and contributions in each iteration from the original YOLO up to YOLOv8, YOLO-NAS, and YOLO with Transformers. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO's development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{ultralytics,
  title = {Ultralytics | {{Revolutionizing}} the {{World}} of {{Vision AI}}},
  url = {https://www.ultralytics.com/},
  urldate = {2023-10-10},
  file = {/Users/jonathan/Zotero/storage/E42ZN2YB/www.ultralytics.com.html}
}

@misc{unrated2023,
  title = {Unrated},
  year = {2023},
  month = oct,
  journal = {Valorant Wiki},
  url = {https://valorant.fandom.com/wiki/Unrated},
  urldate = {2023-10-09},
  langid = {english},
  file = {/Users/jonathan/Zotero/storage/MJVXS63N/Unrated.html}
}

@article{zheng2022,
  title = {Video {{Analysis}} in {{Sports}} by {{Lightweight Object Detection Network}} under the {{Background}} of {{Sports Industry Development}}},
  author = {Zheng, Yifei and Zhang, Hongling},
  editor = {Kumar, Vijay},
  year = {2022},
  month = aug,
  journal = {Computational Intelligence and Neuroscience},
  volume = {2022},
  pages = {1--10},
  issn = {1687-5273, 1687-5265},
  doi = {10.1155/2022/3844770},
  urldate = {2023-10-10},
  abstract = {This study uses the video image information in sports video image analysis to realize scientific sports training. In recent years, game video image analysis has referenced athletes' sports training. The sports video analysis is a widely used and effective method. First, the you only look once (YOLO) method is explored in lightweight object detection. Second, a sports motion analysis system based on the YOLO-OSA (you only look once-one-shot aggregation) target detection network is built based on the dense convolutional network (DenseNet) target detection network established by the one-shot aggregation (OSA) connection. Finally, object detection evaluation principles are used to analyze network performance and object detection in sports video. The results show that the more obvious the target feature, the larger the size, and the more motion information contained in the sports category feature, the more obvious the effect of the detected target. The higher the resolution of the sports video image, the higher the model detection accuracy of the YOLO-OSA target detection network, and the richer the visual video information. In sports video analysis, video images of the appropriate resolution are fed into the system. The YOLO-OSA network achieved 21.70\% precision and 54.90\% recall. In general, the YOLO-OSA network has certain pertinence for sports video image analysis, and it improves the detection speed of video analysis. The research and analysis of video in sports under the lightweight target detection network have certain reference significance.},
  langid = {english}
}
